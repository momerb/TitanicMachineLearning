{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../excel_files/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['Survived', 'PassengerId'])\n",
    "y = dataset['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.0000, 0.0000, 0.2570,  ..., 0.0142, 0.0000, 0.0000],\n",
       "         [1.0000, 1.0000, 0.4453,  ..., 0.1391, 1.0000, 0.0000],\n",
       "         [3.0000, 1.0000, 0.3041,  ..., 0.0155, 0.0000, 1.0000],\n",
       "         ...,\n",
       "         [3.0000, 1.0000, 0.3450,  ..., 0.0458, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.3041,  ..., 0.0586, 1.0000, 1.0000],\n",
       "         [3.0000, 0.0000, 0.3747,  ..., 0.0151, 2.0000, 1.0000]],\n",
       "        device='mps:0'),\n",
       " tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 1., 0.], device='mps:0'),\n",
       " torch.Size([891, 8]),\n",
       " torch.Size([891]),\n",
       " device(type='mps', index=0),\n",
       " device(type='mps', index=0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = torch.tensor(X.values, dtype=torch.float).to(device)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float).to(device)\n",
    "\n",
    "X_tensor, y_tensor, X_tensor.shape, y_tensor.shape, X_tensor.device, y_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,\n",
       " 712,\n",
       " 179,\n",
       " 179,\n",
       " torch.Size([712, 8]),\n",
       " torch.Size([712]),\n",
       " torch.Size([179, 8]),\n",
       " torch.Size([179]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test), X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModelV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=X_train.shape[1], out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=len(y_train.shape))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('layer_stack.0.weight',\n",
       "               tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076],\n",
       "                       [ 0.3117, -0.2594,  0.3073,  0.0662,  0.2612,  0.0479,  0.1705, -0.0499],\n",
       "                       [ 0.2725,  0.0523, -0.1651,  0.0901, -0.1629, -0.0415, -0.1436,  0.2345],\n",
       "                       [-0.2791, -0.1630, -0.0998, -0.2126,  0.0334, -0.3492,  0.3193, -0.3003],\n",
       "                       [ 0.2730,  0.0588, -0.1148,  0.2185,  0.0551,  0.2857,  0.0387, -0.1115],\n",
       "                       [ 0.0950, -0.0959,  0.1488,  0.3157,  0.2044, -0.1546,  0.2041,  0.0633],\n",
       "                       [ 0.1795, -0.2155, -0.3500, -0.1366, -0.2712,  0.2901,  0.1018,  0.1464],\n",
       "                       [ 0.1118, -0.0062,  0.2767, -0.2512,  0.0223, -0.2413,  0.1090, -0.1218],\n",
       "                       [ 0.1083, -0.0737,  0.2932, -0.2096, -0.2109, -0.2109,  0.3180,  0.1178],\n",
       "                       [ 0.3402, -0.2918, -0.3507, -0.2766, -0.2378,  0.1432,  0.1266,  0.2938],\n",
       "                       [-0.1826, -0.2410,  0.1876, -0.1429,  0.2146, -0.0839,  0.2022, -0.2747],\n",
       "                       [-0.1784,  0.1078,  0.0747, -0.0901,  0.2107,  0.2403, -0.2564, -0.1888],\n",
       "                       [ 0.3237, -0.1193, -0.1253, -0.3421, -0.2025,  0.0883, -0.0467, -0.2566],\n",
       "                       [ 0.0083, -0.2415, -0.3000, -0.1947, -0.3094, -0.2251,  0.3534,  0.0668],\n",
       "                       [ 0.1090, -0.3298, -0.2322, -0.1177,  0.0553, -0.3111, -0.1523, -0.2117],\n",
       "                       [ 0.0010, -0.1316, -0.0245, -0.2396, -0.2427, -0.2063, -0.1210, -0.2791],\n",
       "                       [ 0.2964, -0.0702,  0.3042,  0.1102, -0.2994,  0.2447, -0.0973, -0.1355],\n",
       "                       [-0.2935, -0.3515,  0.1012, -0.0772,  0.1376, -0.2901,  0.2625, -0.2595],\n",
       "                       [-0.0610,  0.0738,  0.1825,  0.2854,  0.3221, -0.2803,  0.0890, -0.1521],\n",
       "                       [-0.0387, -0.2646,  0.3220, -0.2595,  0.1890,  0.1243,  0.1149, -0.1911],\n",
       "                       [ 0.3214,  0.0777,  0.0455, -0.3116,  0.1484, -0.0530, -0.1620,  0.3037],\n",
       "                       [ 0.0788, -0.1956, -0.1789, -0.0169,  0.1974, -0.0903, -0.2017, -0.1211],\n",
       "                       [-0.2641,  0.1261,  0.2737, -0.3328,  0.0821,  0.1826,  0.0641, -0.1259],\n",
       "                       [ 0.1845,  0.1858,  0.1322, -0.0621, -0.0936,  0.0378, -0.0625, -0.1054],\n",
       "                       [ 0.2260,  0.3038, -0.0350, -0.0792,  0.0052, -0.0211,  0.0850,  0.0991],\n",
       "                       [-0.3211, -0.1305,  0.2977,  0.1377, -0.0176, -0.2132, -0.2163, -0.3167],\n",
       "                       [-0.1152,  0.1194,  0.2254,  0.1632, -0.3125, -0.2126, -0.0558,  0.3420],\n",
       "                       [ 0.0511, -0.0916,  0.1463, -0.1347, -0.2288,  0.2581, -0.1608, -0.0709],\n",
       "                       [-0.3517,  0.2366,  0.2679,  0.1289, -0.2465, -0.3489, -0.2871,  0.2636],\n",
       "                       [ 0.1697,  0.2975,  0.1852,  0.0895, -0.0035, -0.2689, -0.3029, -0.3307],\n",
       "                       [ 0.1447, -0.1736, -0.0712, -0.2035, -0.0644, -0.2488, -0.2310,  0.1173],\n",
       "                       [-0.1051,  0.2183, -0.1134, -0.2594, -0.0624, -0.1714, -0.1082, -0.3366]],\n",
       "                      device='mps:0')),\n",
       "              ('layer_stack.0.bias',\n",
       "               tensor([ 0.1978, -0.2461,  0.1777,  0.1604,  0.2526, -0.2712,  0.2543, -0.1671,\n",
       "                        0.1312,  0.3320, -0.0499, -0.0027, -0.0814, -0.2952,  0.1697, -0.3510,\n",
       "                        0.2195,  0.2645,  0.3344, -0.0834, -0.2905,  0.0795,  0.1953, -0.3519,\n",
       "                       -0.0803, -0.2119, -0.0309, -0.1740, -0.1445, -0.1122, -0.3360,  0.2901],\n",
       "                      device='mps:0')),\n",
       "              ('layer_stack.2.weight',\n",
       "               tensor([[ 0.1482, -0.0277, -0.0201,  ...,  0.1743, -0.0271,  0.0367],\n",
       "                       [-0.1229, -0.0364,  0.1309,  ...,  0.0428,  0.0487,  0.0969],\n",
       "                       [ 0.1344,  0.0984, -0.1753,  ..., -0.1247,  0.0662,  0.1496],\n",
       "                       ...,\n",
       "                       [ 0.1325,  0.0019,  0.0852,  ...,  0.0193, -0.1634, -0.0192],\n",
       "                       [-0.0802,  0.0172, -0.0205,  ...,  0.0975,  0.0300,  0.0582],\n",
       "                       [-0.1279, -0.0442, -0.0169,  ...,  0.0005,  0.0568,  0.1647]],\n",
       "                      device='mps:0')),\n",
       "              ('layer_stack.2.bias',\n",
       "               tensor([ 0.0518, -0.0402,  0.1588, -0.0673, -0.0513,  0.0121, -0.1346,  0.0192,\n",
       "                       -0.1199,  0.0182,  0.0169,  0.0245, -0.1491, -0.1679,  0.0813,  0.1516,\n",
       "                       -0.1569,  0.0655, -0.1301,  0.0111,  0.1645,  0.1341, -0.1292,  0.1093,\n",
       "                        0.0923, -0.0003,  0.1712, -0.0702, -0.0411, -0.0893,  0.0254,  0.0468],\n",
       "                      device='mps:0')),\n",
       "              ('layer_stack.4.weight',\n",
       "               tensor([[ 0.0141, -0.0995, -0.0796,  0.0601, -0.1550, -0.0275, -0.0039, -0.0716,\n",
       "                         0.0643,  0.0114,  0.1241, -0.0157, -0.1116,  0.1249,  0.0247, -0.0506,\n",
       "                        -0.1165,  0.0414, -0.1686,  0.0466,  0.0874, -0.1551, -0.1157, -0.1271,\n",
       "                         0.1486,  0.1503,  0.0111,  0.1660, -0.0591, -0.1716,  0.0617,  0.0626]],\n",
       "                      device='mps:0')),\n",
       "              ('layer_stack.4.bias', tensor([0.1733], device='mps:0'))]),\n",
       " TitanicModelV0(\n",
       "   (layer_stack): Sequential(\n",
       "     (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = TitanicModelV0()\n",
    "model_0.to(device)\n",
    "\n",
    "model_0.state_dict(), model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(params=model_0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1000/9000] | loss = 0.3396 | acc = 85.53% | test_loss = 0.5073 | test_acc = 79.89%\n",
      "Epoch: [2000/9000] | loss = 0.2939 | acc = 87.64% | test_loss = 0.5684 | test_acc = 82.12%\n",
      "Epoch: [3000/9000] | loss = 0.2775 | acc = 88.48% | test_loss = 0.6834 | test_acc = 83.24%\n",
      "Epoch: [4000/9000] | loss = 0.2665 | acc = 88.76% | test_loss = 0.7996 | test_acc = 87.15%\n",
      "Epoch: [5000/9000] | loss = 0.2594 | acc = 89.33% | test_loss = 0.8949 | test_acc = 86.03%\n",
      "Epoch: [6000/9000] | loss = 0.2543 | acc = 89.19% | test_loss = 0.9974 | test_acc = 84.92%\n",
      "Epoch: [7000/9000] | loss = 0.2502 | acc = 89.61% | test_loss = 1.0955 | test_acc = 84.36%\n",
      "Epoch: [8000/9000] | loss = 0.2471 | acc = 89.33% | test_loss = 1.1979 | test_acc = 84.36%\n",
      "Epoch: [9000/9000] | loss = 0.2447 | acc = 89.89% | test_loss = 1.3060 | test_acc = 84.92%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 9000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    y_logits = model_0(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))  # Prediction thresholding for accuracy calculation\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_0(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: [{epoch + 1}/{epochs}] | {loss = :.4f} | {acc = :.2f}% | {test_loss = :.4f} | {test_acc = :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"titanic_model_0.pth\"\n",
    "MODEL_PATH = Path(\"../models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset = pd.read_csv(\"../excel_files/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_result = result_dataset.drop(columns=['PassengerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_result_tensor = torch.tensor(X_result.values, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_result_logits = model_0(X_result_tensor)\n",
    "\n",
    "y_result_labels = torch.round(torch.sigmoid(y_result_logits)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result_labels = y_result_labels.cpu().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset['Survived'] = y_result_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset.to_csv(\"../excel_files/final_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_competition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
